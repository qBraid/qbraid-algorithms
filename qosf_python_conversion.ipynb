{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "384e875b-f354-47e3-93be-a2833bd5d47d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/Braket/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import bloqade\n",
    "# from bloqade import KrylovKit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b09e1581-ce05-499f-9d20-81b928d80be3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "dim_pca = 10\n",
    "Δ_max = 6.0\n",
    "num_examples = 1000\n",
    "num_test_examples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98344ae5-5055-45a5-acea-133898451f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76522421-817d-4ff1-b514-0861e1290da0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d3d73cd-b187-46df-9e96-e66b832f9d49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform PCA on training data\n",
    "pca = PCA(n_components=dim_pca)\n",
    "x_train_pca = pca.fit_transform(train_dataset.data.numpy().reshape(-1, 28*28))\n",
    "x_test_pca = pca.transform(test_dataset.data.numpy().reshape(-1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02936fa6-32f5-4085-8e6f-d78d84c76540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scale PCA values to feasible range of local detuning\n",
    "x_train_pca = x_train_pca / np.max(np.abs(x_train_pca)) * Δ_max\n",
    "x_test_pca = x_test_pca / np.max(np.abs(x_test_pca)) * Δ_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d2e9596-a5ed-4176-a786-33de409f6d50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.88088681, -0.1077645 , -0.78267303, ...,  1.18395488,\n",
       "        -1.00375497, -0.46647276],\n",
       "       [-2.40351538, -0.38411485,  1.00276769, ...,  0.58196908,\n",
       "         0.37119781, -0.21784087],\n",
       "       [-1.08367033,  0.1664487 ,  0.65421782, ..., -0.2765957 ,\n",
       "         0.24811255, -0.3418475 ],\n",
       "       ...,\n",
       "       [ 1.50126648,  0.89318566, -1.04370463, ..., -0.88698179,\n",
       "        -0.06128021, -2.01555388],\n",
       "       [-0.27316387,  1.61689005, -0.63724006, ...,  0.41777847,\n",
       "         0.67804019, -0.54465725],\n",
       "       [-0.22766553,  1.77605246,  2.12734287, ..., -1.06862189,\n",
       "         0.43011495,  0.13571932]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pca[:, 1:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce2224e6-2296-4ad0-bf79-89c62fe52e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_train = encoder.fit_transform(train_dataset.targets.numpy().reshape(-1, 1))\n",
    "y_test = encoder.transform(test_dataset.targets.numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3499830-b177-4cc5-87ac-77d1f47b8381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:, 1:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5530692e-88d3-4200-ba84-0f2d37251010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define quantum reservoir computing (QRC) layer\n",
    "class DetuningLayer(nn.Module):\n",
    "    def __init__(self, atoms, readouts, Ω, t_start, t_end, step):\n",
    "        super(DetuningLayer, self).__init__()\n",
    "        self.atoms = atoms\n",
    "        self.readouts = readouts\n",
    "        self.Ω = Ω\n",
    "        self.t_start = t_start\n",
    "        self.t_end = t_end\n",
    "        self.step = step\n",
    "    def forward(self, x):\n",
    "    # Simulate quantum dynamics and compute readouts\n",
    "    # have to use bloqade quantum\n",
    "    # This part is not implemented in Python, as it requires a quantum simulator    \n",
    "    # calculating steps\n",
    "        self.atoms @ np.exp(-1j * h * (self.t_end - self.t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef6e17-5d42-4f2f-a9f4-81506b792d71",
   "metadata": {},
   "source": [
    "## Defining a NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd603eb8-c7d3-47b5-9b93-11951e05d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim_pca, 10)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "    # Train classical model using PCA features\n",
    "    model_reg = Net()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model_reg.parameters(), lr=0.01)\n",
    "    for epoch in range(1000):\n",
    "        for x, y in train_loader:\n",
    "            x = x.view(-1, 28*28)\n",
    "            x_pca = pca.transform(x.numpy())\n",
    "            x_pca = torch.tensor(x_pca, dtype=torch.float32)\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "            optimizer.zero_grad()\n",
    "            output = model_reg(x_pca)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    # Train QRC model using quantum reservoir computing\n",
    "    pre_layer = DetuningLayer(atoms, readouts, Ω, t_start, t_end, step)\n",
    "    model_qrc = Net()\n",
    "    for epoch in range(1000):\n",
    "        for x, y in train_loader:\n",
    "            x = x.view(-1, 28*28)\n",
    "            x_pca = pca.transform(x.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_braket",
   "language": "python",
   "name": "conda_braket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
